{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "    getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#to make matplotlib figures appear inline in the notebook\n",
    "#rather than in a new window.\n",
    "# matplotlib inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "#Set NotebookApp.iopub_data_rate_limit=10000000 while starting Jupyter or else fetch error\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# print('X_train shape:', X_train.shape)\n",
    "# print('X_test shape:', X_test.shape)\n",
    "\n",
    "# Visualize some example from the dataset.\n",
    "# We show a few examples of training image from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog','frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 train samples\n",
      "2000 validation samples\n",
      "1000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "num_validation = 2000\n",
    "mask = [-(i+1) for i in range(num_validation)]\n",
    "X_validation = X_train[mask]\n",
    "y_validation = y_train[mask]\n",
    "num_test = 1000\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_validation.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "nb_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_validation = np_utils.to_categorical(y_validation, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the CNN\n",
    "model = Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "# please put your code here\n",
    "#Adding the convolutional layer with filters=16, kernal size of 5x5, strides=1 and padding='same'. Relu is used as the activation function\n",
    "model.add(Convolution2D(filters = 16, kernel_size = (5, 5), strides = 1, padding = 'same', activation = 'relu', input_shape = (32, 32, 3)))\n",
    "#Maxpooling the data by reducing the dimensions by half\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = None, padding = 'same'))\n",
    "print('maxpool done')\n",
    "#Adding the convolutional layer with filters=32, kernal size of 5x5, strides=1 and padding='same'. Relu is used as the activation function\n",
    "model.add(Convolution2D(filters = 32, kernel_size = (5, 5) , strides = 1, padding = 'same', activation = 'relu',))\n",
    "#Adding the convolutional layer with filters=64, kernal size of 5x5, strides=1 and padding='same'. Relu is used as the activation function\n",
    "model.add(Convolution2D(filters = 64, kernel_size = (5, 5) , strides = 1, padding = 'same', activation = 'relu',))\n",
    "#Maxpooling the data by reducing the dimensions by half\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = None, padding = 'same'))\n",
    "#Deactivation 10% of the nodes\n",
    "model.add(Dropout(rate = 0.9))\n",
    "print('dropout done')\n",
    "#Flattening the data in a vector form\n",
    "model.add(Flatten())\n",
    "#Using the activation function as softmax to add the dense (fully connected) layer\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "#Compiling the data with the Adam, SGD or RMSprop optimizers\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.0001, decay = 1e-6), metrics = ['accuracy'])\n",
    "# print(X_train)\n",
    "# print(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\users\\weka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 12.0520 - acc: 0.1212 - val_loss: 9.8387 - val_acc: 0.1660\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 6.9852 - acc: 0.1748 - val_loss: 4.3068 - val_acc: 0.2465\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 3.3280 - acc: 0.2202 - val_loss: 2.8834 - val_acc: 0.2450\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.3642 - acc: 0.2592 - val_loss: 1.9782 - val_acc: 0.3220\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.0170 - acc: 0.3106 - val_loss: 1.7834 - val_acc: 0.3710\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.8137 - acc: 0.3744 - val_loss: 1.7303 - val_acc: 0.3905\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.6765 - acc: 0.4080 - val_loss: 1.6014 - val_acc: 0.4280\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 1.5540 - acc: 0.4598 - val_loss: 1.4609 - val_acc: 0.4840\n",
      "Epoch 9/30\n",
      "2816/5000 [===============>..............] - ETA: 3s - loss: 1.4552 - acc: 0.4883"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train_history = model.fit(X_train, Y_train, batch_size = 128, shuffle = True, epochs = 30, validation_data = (X_validation, Y_validation), callbacks = [EarlyStopping(min_delta = 0.001, patience = 3)])\n",
    "print(train_history.history)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Convolution2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# model.add(Convolution2D(64, kernel_size=(3, 3), activation='tanh'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "# train_history = model.fit(X_train, Y_train, batch_size=128, shuffle=True,\n",
    "#     epochs=30, validation_data=(X_validation, Y_validation),\n",
    "# callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
