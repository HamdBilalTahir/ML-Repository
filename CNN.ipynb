{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and\n",
    "    getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#to make matplotlib figures appear inline in the notebook\n",
    "#rather than in a new window.\n",
    "# matplotlib inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "#Set NotebookApp.iopub_data_rate_limit=10000000 while starting Jupyter or else fetch error\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "# print('X_train shape:', X_train.shape)\n",
    "# print('X_test shape:', X_test.shape)\n",
    "\n",
    "# Visualize some example from the dataset.\n",
    "# We show a few examples of training image from each class.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog','frog', 'horse', 'ship', 'truck']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 train samples\n",
      "2000 validation samples\n",
      "1000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Subsample the data for more efficient code execution in this exercise\n",
    "num_training = 5000\n",
    "mask = list(range(num_training))\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "num_validation = 2000\n",
    "mask = [-(i+1) for i in range(num_validation)]\n",
    "X_validation = X_train[mask]\n",
    "y_validation = y_train[mask]\n",
    "num_test = 1000\n",
    "mask = list(range(num_test))\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_validation.shape[0], 'validation samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "nb_classes = 10\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_validation = np_utils.to_categorical(y_validation, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\users\\weka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "maxpool done\n",
      "WARNING:tensorflow:From d:\\users\\weka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "dropout done\n"
     ]
    }
   ],
   "source": [
    "## build the CNN\n",
    "model = Sequential()\n",
    "\n",
    "model = Sequential()\n",
    "# please put your code here\n",
    "#Adding the convolutional layer with filters=16, kernal size of 5x5, strides=1 and padding='same'. Relu is used as the activation function\n",
    "model.add(Convolution2D(filters = 16, kernel_size = (5, 5), strides = 1, padding = 'same', activation = 'relu', input_shape = (32, 32, 3)))\n",
    "#Maxpooling the data by reducing the dimensions by half\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = None, padding = 'same'))\n",
    "print('maxpool done')\n",
    "#Adding the convolutional layer with filters=32, kernal size of 5x5, strides=1 and padding='same'. Relu is used as the activation function\n",
    "model.add(Convolution2D(filters = 32, kernel_size = (5, 5) , strides = 1, padding = 'same', activation = 'relu',))\n",
    "#Adding the convolutional layer with filters=64, kernal size of 5x5, strides=1 and padding='same'. Relu is used as the activation function\n",
    "model.add(Convolution2D(filters = 64, kernel_size = (5, 5) , strides = 1, padding = 'same', activation = 'relu',))\n",
    "#Maxpooling the data by reducing the dimensions by half\n",
    "model.add(MaxPooling2D(pool_size = (2,2), strides = None, padding = 'same'))\n",
    "#Deactivation 10% of the nodes\n",
    "model.add(Dropout(rate = 0.9))\n",
    "print('dropout done')\n",
    "#Flattening the data in a vector form\n",
    "model.add(Flatten())\n",
    "#Using the activation function as softmax to add the dense (fully connected) layer\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "#Compiling the data with the Adam, SGD or RMSprop optimizers\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.0001, decay = 1e-6), metrics = ['accuracy'])\n",
    "# print(X_train)\n",
    "# print(Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\users\\weka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 5000 samples, validate on 2000 samples\n",
      "Epoch 1/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 14.0859 - acc: 0.1018 - val_loss: 11.5852 - val_acc: 0.1185\n",
      "Epoch 2/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 13.9534 - acc: 0.1030 - val_loss: 11.7009 - val_acc: 0.1140\n",
      "Epoch 3/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 13.7190 - acc: 0.1006 - val_loss: 7.6969 - val_acc: 0.1640\n",
      "Epoch 4/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 12.8405 - acc: 0.1118 - val_loss: 6.2554 - val_acc: 0.1555\n",
      "Epoch 5/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 10.7625 - acc: 0.1172 - val_loss: 2.8880 - val_acc: 0.1810\n",
      "Epoch 6/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 4.7138 - acc: 0.1166 - val_loss: 2.2778 - val_acc: 0.1340\n",
      "Epoch 7/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.4787 - acc: 0.1080 - val_loss: 2.2815 - val_acc: 0.1505\n",
      "Epoch 8/30\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 2.3287 - acc: 0.1264 - val_loss: 2.2788 - val_acc: 0.1780\n",
      "Epoch 9/30\n",
      "5000/5000 [==============================] - 11s 2ms/step - loss: 2.3040 - acc: 0.1266 - val_loss: 2.2745 - val_acc: 0.2000\n",
      "Epoch 10/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2952 - acc: 0.1224 - val_loss: 2.2620 - val_acc: 0.1965\n",
      "Epoch 11/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2879 - acc: 0.1358 - val_loss: 2.2594 - val_acc: 0.2135\n",
      "Epoch 12/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2827 - acc: 0.1374 - val_loss: 2.2443 - val_acc: 0.2195\n",
      "Epoch 13/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2710 - acc: 0.1558 - val_loss: 2.2289 - val_acc: 0.2320\n",
      "Epoch 14/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2732 - acc: 0.1390 - val_loss: 2.2289 - val_acc: 0.2455\n",
      "Epoch 15/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2645 - acc: 0.1552 - val_loss: 2.2026 - val_acc: 0.2505\n",
      "Epoch 16/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2523 - acc: 0.1630 - val_loss: 2.1986 - val_acc: 0.2550\n",
      "Epoch 17/30\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 2.2485 - acc: 0.1580 - val_loss: 2.1763 - val_acc: 0.2645\n",
      "Epoch 18/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2300 - acc: 0.1652 - val_loss: 2.1352 - val_acc: 0.2745\n",
      "Epoch 19/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.2191 - acc: 0.1728 - val_loss: 2.1233 - val_acc: 0.2825\n",
      "Epoch 20/30\n",
      "5000/5000 [==============================] - 11s 2ms/step - loss: 2.2041 - acc: 0.1862 - val_loss: 2.1141 - val_acc: 0.2915\n",
      "Epoch 21/30\n",
      "5000/5000 [==============================] - 11s 2ms/step - loss: 2.1996 - acc: 0.1808 - val_loss: 2.0861 - val_acc: 0.2915\n",
      "Epoch 22/30\n",
      "5000/5000 [==============================] - 12s 2ms/step - loss: 2.1812 - acc: 0.2014 - val_loss: 2.0716 - val_acc: 0.3035\n",
      "Epoch 23/30\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 2.1800 - acc: 0.1936 - val_loss: 2.0610 - val_acc: 0.3105\n",
      "Epoch 24/30\n",
      "5000/5000 [==============================] - 11s 2ms/step - loss: 2.1553 - acc: 0.2002 - val_loss: 2.0214 - val_acc: 0.3035\n",
      "Epoch 25/30\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 2.1414 - acc: 0.1958 - val_loss: 2.0242 - val_acc: 0.3105\n",
      "Epoch 26/30\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 2.1340 - acc: 0.2140 - val_loss: 1.9932 - val_acc: 0.3050\n",
      "Epoch 27/30\n",
      "1792/5000 [=========>....................] - ETA: 5s - loss: 2.1556 - acc: 0.2048- ETA: 6s - loss: 2.1747 - acc: 0."
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "train_history = model.fit(X_train, Y_train, batch_size = 128, shuffle = True, epochs = 30, validation_data = (X_validation, Y_validation), callbacks = [EarlyStopping(min_delta = 0.001, patience = 3)])\n",
    "print(train_history.history)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model.add(Convolution2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "# model.add(Convolution2D(64, kernel_size=(3, 3), activation='tanh'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "# train_history = model.fit(X_train, Y_train, batch_size=128, shuffle=True,\n",
    "#     epochs=30, validation_data=(X_validation, Y_validation),\n",
    "# callbacks=[EarlyStopping(min_delta=0.001, patience=3)])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
