{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('./Multi-Domain Sentiment Dataset Amazon Products', ['sorted_data'], [])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data', ['apparel', 'automotive', 'baby', 'beauty', 'books', 'camera_&_photo', 'cell_phones_&_service', 'computer_&_video_games', 'dvd', 'electronics', 'gourmet_food', 'grocery', 'health_&_personal_care', 'jewelry_&_watches', 'kitchen_&_housewares', 'magazines', 'music', 'musical_instruments', 'office_products', 'outdoor_living', 'software', 'sports_&_outdoors', 'tools_&_hardware', 'toys_&_games', 'video'], ['stopwords', 'summary.txt'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\apparel', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\automotive', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\baby', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\beauty', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\books', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\camera_&_photo', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\cell_phones_&_service', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\computer_&_video_games', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\dvd', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\electronics', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\gourmet_food', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\grocery', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\health_&_personal_care', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\jewelry_&_watches', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\kitchen_&_housewares', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\magazines', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\music', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'processed.review.random', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\musical_instruments', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\office_products', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\outdoor_living', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\software', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\sports_&_outdoors', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\tools_&_hardware', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\toys_&_games', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n",
      "('./Multi-Domain Sentiment Dataset Amazon Products\\\\sorted_data\\\\video', [], ['all.review', 'negative.review', 'positive.review', 'processed.review', 'processed.review.balanced', 'unlabeled.review'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = './Multi-Domain Sentiment Dataset Amazon Products'\n",
    "files=[]\n",
    "for d in os.walk(directory):\n",
    "    files.append(d)\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apparel',\n",
       " 'automotive',\n",
       " 'baby',\n",
       " 'beauty',\n",
       " 'books',\n",
       " 'camera_&_photo',\n",
       " 'cell_phones_&_service',\n",
       " 'computer_&_video_games',\n",
       " 'dvd',\n",
       " 'electronics',\n",
       " 'gourmet_food',\n",
       " 'grocery',\n",
       " 'health_&_personal_care',\n",
       " 'jewelry_&_watches',\n",
       " 'kitchen_&_housewares',\n",
       " 'magazines',\n",
       " 'music',\n",
       " 'musical_instruments',\n",
       " 'office_products',\n",
       " 'outdoor_living',\n",
       " 'software',\n",
       " 'sports_&_outdoors',\n",
       " 'tools_&_hardware',\n",
       " 'toys_&_games',\n",
       " 'video']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = files[1][1]\n",
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\weka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \"\"\"\n",
      "d:\\users\\weka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rev_pos = []\n",
    "rev_neg = []\n",
    "for product in products:\n",
    "    dir = './Multi-Domain Sentiment Dataset Amazon Products/sorted_data'+'/'+product\n",
    "    pos = pd.read_csv(dir+'/positive.review', header = None,sep='delimiter')\n",
    "    neg = pd.read_csv(dir+'/negative.review', header = None,sep='delimiter')\n",
    "    rev_pos.append(pos)\n",
    "    rev_neg.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                              <review>\n",
       "1                                           <unique_id>\n",
       "2              B0009N4F6I:works_very_well:i_have_9_cats\n",
       "3                                          </unique_id>\n",
       "4                                           <unique_id>\n",
       "5                                                201600\n",
       "6                                          </unique_id>\n",
       "7                                                <asin>\n",
       "8                                            B0009N4F6I\n",
       "9                                               </asin>\n",
       "10                                       <product_name>\n",
       "11                        Wedgie Cup Holder: Automotive\n",
       "12                                      </product_name>\n",
       "13                                       <product_type>\n",
       "14                                           automotive\n",
       "15                                      </product_type>\n",
       "16                                       <product_type>\n",
       "17                                           automotive\n",
       "18                                      </product_type>\n",
       "19                                            <helpful>\n",
       "20                                               1 of 1\n",
       "21                                           </helpful>\n",
       "22                                             <rating>\n",
       "23                                                  5.0\n",
       "24                                            </rating>\n",
       "25                                              <title>\n",
       "26                                      Works very well\n",
       "27                                             </title>\n",
       "28                                               <date>\n",
       "29                                      August 19, 2006\n",
       "30                                              </date>\n",
       "31                                           <reviewer>\n",
       "32                                        I have 9 cats\n",
       "33                                          </reviewer>\n",
       "34                                  <reviewer_location>\n",
       "35                                          Dela where?\n",
       "36                                 </reviewer_location>\n",
       "37                                        <review_text>\n",
       "38    I bought one today for my Mazda Tribute becaus...\n",
       "39                                       </review_text>\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To see what a typical product reviews dataframe looks like\n",
    "rev_pos[1][0].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing to collect the review text only\n",
    "rev_pos_new = []\n",
    "for df in rev_pos:\n",
    "    ind_pos = df.index[df[0] == '<review_text>'].tolist()\n",
    "    ind_pos = [x+1 for x in ind_pos]\n",
    "    temp_list = df.iloc[ind_pos].values.flatten().tolist()\n",
    "    rev_pos_new.append(temp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_pos_final = []\n",
    "for text_list in rev_pos_new:\n",
    "    n+=len(text_list)\n",
    "    for texts in text_list:\n",
    "        n1+=1\n",
    "        rev_pos_final.append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOOL LIKE ME. AND COMFORTABLE. AND RELATIVELY CHEAP. I'LL ALWAYS KEEP A PAIR OF STAN SMITH'S AROUND FOR WEEKENDS\",\n",
       " 'These sunglasses are all right. They were a little crooked, but still cool..',\n",
       " \"I don't see the difference between these bodysuits and the more expensive ones.  Fits my boy just right\",\n",
       " 'Very nice basic clothing.  I think the size is fine.  I really like being able to find these shades of green, though I have decided the lighter shade is really a feminine color.  This is the only brand that I can find these muted greens',\n",
       " 'I love these socks. They fit great (my 15 month old daughter has thick ankles) and she can zoom around on the kitchen floor and not take a nose dive into things. :',\n",
       " \"Finally I have found a quality brand of swimsuit I can order on line and know it will fit.  I'm a daily swimmer who is long-bodied.  This particular style fit great when it arrived; it arrived quickly within four days; shipping was free; and the lycra material is the most resilient I know given the chlorine bashing my suits get.  Please continue to sell this particular item at a price lower than the sports stores.  Thanks!!\",\n",
       " 'Your company was a pleasure to work with- thanks!  I will enjoy wearing the swimsuit that I ordered',\n",
       " \"very portable. great picture. easy to operate. all the accessories you need. great sound. playes dvd's from sony camcorder. very happy with the system. am looking forward to using this camping and on vacation.\",\n",
       " 'I have been looking for a pair of Docs for a while. I know they are a new globalized company, and I am not necessarily against that.',\n",
       " 'The quality is much better than expected. I bought one for myself and one for my husband prior to our Las Vegas trip Sept. 6, 2005. We were able to walk with or hands free because these fannypacks held all of the necessities, our cell phones, travelers checks, keys, and medicines in particular. We love the spacious divided compartments. I highly reccommend this product..']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_pos_final[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_neg_new = []\n",
    "for df in rev_neg:\n",
    "    ind_neg = df.index[df[0] == '<review_text>'].tolist()\n",
    "    ind_neg = [x+1 for x in ind_neg]\n",
    "    temp_list = df.iloc[ind_neg].values.flatten().tolist()\n",
    "    rev_neg_new.append(temp_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_neg_final = []\n",
    "for text_list in rev_neg_new:\n",
    "    n+=len(text_list)\n",
    "    for texts in text_list:\n",
    "        n1+=1\n",
    "        rev_neg_final.append(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want to start by saying Fred Flare- shipped this product very fast!! And the transaction itself was very smooth. I do however, have extreme problems with the product itself. The product is not leather, its nylon, and it sort of looks cheap? The inside material is sued, but that\\'s only the lining for the base of the wallet. Also, The wallet part is very hard to use. You cant really put too much in the wallet- The credit card slots are a little too snug, and there is no place for my I.D. The wallet included a small \"note book\" but it also doesn\\'t fit in the wallet? I was very excited about this product, but now I feel duped. The pictures made the wallet seem like it was of higher quality, and that it was user friendly, but it\\'s not. I do not recommend this product',\n",
       " \"I have to say that I was disappointed when I opened up the package containing my iPod wallet. It's cute, but not $60ish cute. First of all, it's not leather, it's nylon. The lining is indeed suede, but the photos in the product listing are misleading. I'm keeping it because the hassle of shipping it back, etc. isn't worth it. It does the job, but it wasn't what I was expecting. I feel ripped off\",\n",
       " 'I am sorry but I did not like it nor will I wear it as it is too big & looks funny on me. I wish I had not have gotten it.',\n",
       " \"A red star!?!?  I bet this won't sell well in eastern Europe.\",\n",
       " 'Perhaps it is my own fault for not reading more closely, or failing to question the somewhat ambiguous product description.  The fact is, I thought that I would be receiving 84 plastic stays (3x28), 28 each in 3 different sizes.  At $8.00, that seemed like a reasonable deal for plastic collar stays.  What I got, and I confess that the product description could be interpreted this way, was a total of 28 stays in assorted sizes.  When you add in the $4.00 I was charged for shipping (actual US Postal Service postage on the package was $1.84), this really is a poor deal compared to other available options.  About 43 cents for each plastic collar stay?  A bad choice',\n",
       " \"THe pants that I ordered for my size were very small. They weren't true to size at all. I would not recommend this item to anyone\",\n",
       " 'I ordered the black one. According to the photo provided, it was supposed to be black with white seams, but when i received it, it was all black. Once I put it on it fitted perfectly. But it is simply too difficult to put on even though it is the right size.',\n",
       " 'Suit was too small, not enough information available on the site for it. I called Amazon, but even the customer representative was not sure the size. I bought the suit as he suggested, but it is too small',\n",
       " \"the swim suit was so unsatisfactory looking that I didn't even try it on.  it was blue striped with a totally different blue strap that didn't go with the main color of the suit.  Very poor choice for a grab bag.  Taught me not to use grab bag shopping from this company\",\n",
       " 'IT was advertised and NOT IN STOCK so I was unable to get it']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_neg_final[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'europarl_raw', 'europarl_raw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet', 'wordnet.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "# nltk.download() \n",
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Refine the review texts and remove characters\n",
    "rev_pos_refined = []\n",
    "for rev in rev_pos_final:\n",
    "    rev_one_string = rev\n",
    "    rev_one_string = rev_one_string.replace(' ,',',')\n",
    "    rev_one_string = rev_one_string.replace(' .',',')\n",
    "    rev_one_string = rev_one_string.replace(\"\\' \",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\"(\",\"\")\n",
    "    rev_one_string = rev_one_string.replace(\")\",\"\")\n",
    "    rev_pos_refined.append(rev_one_string)\n",
    "# rev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"GOOD LOOKING KICKS IF YOUR KICKIN IT OLD SCHOOL LIKE ME. AND COMFORTABLE. AND RELATIVELY CHEAP. I'LL ALWAYS KEEP A PAIR OF STAN SMITH'S AROUND FOR WEEKENDS\",\n",
       " 'These sunglasses are all right. They were a little crooked, but still cool..',\n",
       " \"I don't see the difference between these bodysuits and the more expensive ones.  Fits my boy just right\",\n",
       " 'Very nice basic clothing.  I think the size is fine.  I really like being able to find these shades of green, though I have decided the lighter shade is really a feminine color.  This is the only brand that I can find these muted greens',\n",
       " 'I love these socks. They fit great my 15 month old daughter has thick ankles and she can zoom around on the kitchen floor and not take a nose dive into things. :',\n",
       " \"Finally I have found a quality brand of swimsuit I can order on line and know it will fit.  I'm a daily swimmer who is long-bodied.  This particular style fit great when it arrived; it arrived quickly within four days; shipping was free; and the lycra material is the most resilient I know given the chlorine bashing my suits get.  Please continue to sell this particular item at a price lower than the sports stores.  Thanks!!\",\n",
       " 'Your company was a pleasure to work with- thanks!  I will enjoy wearing the swimsuit that I ordered',\n",
       " \"very portable. great picture. easy to operate. all the accessories you need. great sound. playes dvd's from sony camcorder. very happy with the system. am looking forward to using this camping and on vacation.\",\n",
       " 'I have been looking for a pair of Docs for a while. I know they are a new globalized company, and I am not necessarily against that.',\n",
       " 'The quality is much better than expected. I bought one for myself and one for my husband prior to our Las Vegas trip Sept. 6, 2005. We were able to walk with or hands free because these fannypacks held all of the necessities, our cell phones, travelers checks, keys, and medicines in particular. We love the spacious divided compartments. I highly reccommend this product..']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_pos_refined[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_neg_refined = []\n",
    "for rev in rev_neg_final:\n",
    "    rev_one_string = rev\n",
    "    rev_one_string = rev_one_string.replace(' ,',',')\n",
    "    rev_one_string = rev_one_string.replace(' .',',')\n",
    "    rev_one_string = rev_one_string.replace(\"\\' \",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\"(\",\"\")\n",
    "    rev_one_string = rev_one_string.replace(\")\",\"\")\n",
    "    rev_neg_refined.append(rev_one_string)\n",
    "# rev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I want to start by saying Fred Flare- shipped this product very fast!! And the transaction itself was very smooth. I do however, have extreme problems with the product itself. The product is not leather, its nylon, and it sort of looks cheap? The inside material is sued, but that\\'s only the lining for the base of the wallet. Also, The wallet part is very hard to use. You cant really put too much in the wallet- The credit card slots are a little too snug, and there is no place for my I.D. The wallet included a small \"note book\" but it also doesn\\'t fit in the wallet? I was very excited about this product, but now I feel duped. The pictures made the wallet seem like it was of higher quality, and that it was user friendly, but it\\'s not. I do not recommend this product',\n",
       " \"I have to say that I was disappointed when I opened up the package containing my iPod wallet. It's cute, but not $60ish cute. First of all, it's not leather, it's nylon. The lining is indeed suede, but the photos in the product listing are misleading. I'm keeping it because the hassle of shipping it back, etc. isn't worth it. It does the job, but it wasn't what I was expecting. I feel ripped off\",\n",
       " 'I am sorry but I did not like it nor will I wear it as it is too big & looks funny on me. I wish I had not have gotten it.',\n",
       " \"A red star!?!?  I bet this won't sell well in eastern Europe.\",\n",
       " 'Perhaps it is my own fault for not reading more closely, or failing to question the somewhat ambiguous product description.  The fact is, I thought that I would be receiving 84 plastic stays 3x28, 28 each in 3 different sizes.  At $8.00, that seemed like a reasonable deal for plastic collar stays.  What I got, and I confess that the product description could be interpreted this way, was a total of 28 stays in assorted sizes.  When you add in the $4.00 I was charged for shipping actual US Postal Service postage on the package was $1.84, this really is a poor deal compared to other available options.  About 43 cents for each plastic collar stay?  A bad choice',\n",
       " \"THe pants that I ordered for my size were very small. They weren't true to size at all. I would not recommend this item to anyone\",\n",
       " 'I ordered the black one. According to the photo provided, it was supposed to be black with white seams, but when i received it, it was all black. Once I put it on it fitted perfectly. But it is simply too difficult to put on even though it is the right size.',\n",
       " 'Suit was too small, not enough information available on the site for it. I called Amazon, but even the customer representative was not sure the size. I bought the suit as he suggested, but it is too small',\n",
       " \"the swim suit was so unsatisfactory looking that I didn't even try it on.  it was blue striped with a totally different blue strap that didn't go with the main color of the suit.  Very poor choice for a grab bag.  Taught me not to use grab bag shopping from this company\",\n",
       " 'IT was advertised and NOT IN STOCK so I was unable to get it']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_neg_refined[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38548"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Append all reviews in one list\n",
    "rev_list = []\n",
    "for rev in rev_neg_final:\n",
    "    rev_list.append(rev)\n",
    "for rev in rev_pos_final:\n",
    "    rev_list.append(rev)\n",
    "len(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating weights/classifications for all the reviews\n",
    "neg_targets = np.zeros((len(rev_neg_refined),),dtype = np.int)\n",
    "pos_targets = np.ones((len(rev_pos_refined),),dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for neg_tar in neg_targets:\n",
    "    target_list.append(neg_tar)\n",
    "for pos_tar in pos_targets:\n",
    "    target_list.append(pos_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38548"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use bag of words or count vectorizer to make features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer(lowercase = True, stop_words = 'english', min_df = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_vec = count_vec.fit_transform(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38548, 29179)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '007',\n",
       " '00am',\n",
       " '00pm',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '04',\n",
       " '05',\n",
       " '05am',\n",
       " '06',\n",
       " '07',\n",
       " '08',\n",
       " '09',\n",
       " '0x80040273',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '10000',\n",
       " '100asa',\n",
       " '100g',\n",
       " '100lbs',\n",
       " '100mm',\n",
       " '100pk',\n",
       " '100s',\n",
       " '100th',\n",
       " '100x',\n",
       " '101',\n",
       " '1019',\n",
       " '102',\n",
       " '104',\n",
       " '1045',\n",
       " '105',\n",
       " '1050',\n",
       " '105mm',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '1080',\n",
       " '1080i',\n",
       " '1080p',\n",
       " '109',\n",
       " '1099',\n",
       " '10d',\n",
       " '10m',\n",
       " '10mb',\n",
       " '10mm',\n",
       " '10mp',\n",
       " '10pm',\n",
       " '10th',\n",
       " '10x',\n",
       " '10x50',\n",
       " '10yr',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '110v',\n",
       " '111',\n",
       " '113',\n",
       " '114',\n",
       " '115',\n",
       " '117',\n",
       " '118',\n",
       " '11b',\n",
       " '11th',\n",
       " '11yr',\n",
       " '12',\n",
       " '120',\n",
       " '1200',\n",
       " '120v',\n",
       " '120x',\n",
       " '121',\n",
       " '122',\n",
       " '123',\n",
       " '125',\n",
       " '126',\n",
       " '128',\n",
       " '128mb',\n",
       " '129',\n",
       " '12g',\n",
       " '12th',\n",
       " '12v',\n",
       " '12x',\n",
       " '12x12',\n",
       " '13',\n",
       " '130',\n",
       " '1300',\n",
       " '133',\n",
       " '135',\n",
       " '135mm',\n",
       " '139',\n",
       " '13th',\n",
       " '14',\n",
       " '140',\n",
       " '1400',\n",
       " '142',\n",
       " '14570',\n",
       " '148',\n",
       " '149',\n",
       " '14k',\n",
       " '14oz',\n",
       " '14th',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150lbs',\n",
       " '151',\n",
       " '152',\n",
       " '153',\n",
       " '155',\n",
       " '159',\n",
       " '15ft',\n",
       " '15gb',\n",
       " '15mm',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '1600',\n",
       " '162',\n",
       " '165',\n",
       " '16mb',\n",
       " '16mm',\n",
       " '16oz',\n",
       " '16th',\n",
       " '16x',\n",
       " '16x9',\n",
       " '17',\n",
       " '170',\n",
       " '1700',\n",
       " '1706',\n",
       " '171',\n",
       " '175',\n",
       " '178',\n",
       " '17gr',\n",
       " '17th',\n",
       " '18',\n",
       " '180',\n",
       " '1800',\n",
       " '180lbs',\n",
       " '181',\n",
       " '1819',\n",
       " '182',\n",
       " '1830',\n",
       " '184',\n",
       " '1840',\n",
       " '185',\n",
       " '1850',\n",
       " '1862',\n",
       " '1870',\n",
       " '1875',\n",
       " '1879',\n",
       " '1899',\n",
       " '18mm',\n",
       " '18th',\n",
       " '18x',\n",
       " '19',\n",
       " '190',\n",
       " '1900',\n",
       " '1906',\n",
       " '190lb',\n",
       " '1917',\n",
       " '1920',\n",
       " '1920s',\n",
       " '1922',\n",
       " '1924',\n",
       " '1928',\n",
       " '1929',\n",
       " '1930',\n",
       " '1930s',\n",
       " '1931',\n",
       " '1932',\n",
       " '1933',\n",
       " '1934',\n",
       " '1935',\n",
       " '1937',\n",
       " '1938',\n",
       " '1939',\n",
       " '1940',\n",
       " '1940s',\n",
       " '1941',\n",
       " '1942',\n",
       " '1943',\n",
       " '1944',\n",
       " '1945',\n",
       " '1946',\n",
       " '1947',\n",
       " '1948',\n",
       " '1949',\n",
       " '195',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1951',\n",
       " '1952',\n",
       " '1953',\n",
       " '1954',\n",
       " '1955',\n",
       " '1956',\n",
       " '1957',\n",
       " '1959',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1961',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1966',\n",
       " '1967',\n",
       " '1968',\n",
       " '1969',\n",
       " '1970',\n",
       " '1970s',\n",
       " '1971',\n",
       " '1972',\n",
       " '1973',\n",
       " '1974',\n",
       " '1975',\n",
       " '1976',\n",
       " '1977',\n",
       " '1978',\n",
       " '1979',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1981',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1985',\n",
       " '1986',\n",
       " '1987',\n",
       " '1988',\n",
       " '1989',\n",
       " '199',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1d',\n",
       " '1ds',\n",
       " '1gb',\n",
       " '1hr',\n",
       " '1mm',\n",
       " '1mp',\n",
       " '1pk',\n",
       " '1st',\n",
       " '1star',\n",
       " '1x',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '200mm',\n",
       " '201',\n",
       " '2010',\n",
       " '2020',\n",
       " '203',\n",
       " '208',\n",
       " '20d',\n",
       " '20ft',\n",
       " '20g',\n",
       " '20lb',\n",
       " '20mm',\n",
       " '20psi',\n",
       " '20s',\n",
       " '20th',\n",
       " '21',\n",
       " '210',\n",
       " '2100',\n",
       " '212',\n",
       " '213',\n",
       " '215',\n",
       " '21st',\n",
       " '22',\n",
       " '220',\n",
       " '2200',\n",
       " '225',\n",
       " '225b',\n",
       " '22nd',\n",
       " '23',\n",
       " '230',\n",
       " '2300',\n",
       " '2310',\n",
       " '23rd',\n",
       " '24',\n",
       " '240',\n",
       " '2400',\n",
       " '245',\n",
       " '24lb',\n",
       " '24mm',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '2500',\n",
       " '250d',\n",
       " '250gb',\n",
       " '250lbs',\n",
       " '256',\n",
       " '256mb',\n",
       " '25c',\n",
       " '25th',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '26th',\n",
       " '27',\n",
       " '270',\n",
       " '275',\n",
       " '27th',\n",
       " '28',\n",
       " '280',\n",
       " '28mm',\n",
       " '28th',\n",
       " '29',\n",
       " '299',\n",
       " '2am',\n",
       " '2c',\n",
       " '2cd',\n",
       " '2d',\n",
       " '2g',\n",
       " '2gb',\n",
       " '2ghz',\n",
       " '2hrs',\n",
       " '2k',\n",
       " '2k5',\n",
       " '2k6',\n",
       " '2lb',\n",
       " '2mb',\n",
       " '2mm',\n",
       " '2mp',\n",
       " '2nd',\n",
       " '2pac',\n",
       " '2star',\n",
       " '2t',\n",
       " '2x',\n",
       " '2x4s',\n",
       " '2yr',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '300d',\n",
       " '300mm',\n",
       " '301',\n",
       " '303',\n",
       " '305',\n",
       " '30d',\n",
       " '30g',\n",
       " '30gb',\n",
       " '30min',\n",
       " '30mm',\n",
       " '30pm',\n",
       " '30s',\n",
       " '30th',\n",
       " '31',\n",
       " '310',\n",
       " '3122a',\n",
       " '3130',\n",
       " '31g',\n",
       " '31st',\n",
       " '32',\n",
       " '320',\n",
       " '3200',\n",
       " '320mm',\n",
       " '320x240',\n",
       " '325',\n",
       " '32mb',\n",
       " '32oz',\n",
       " '33',\n",
       " '333',\n",
       " '34',\n",
       " '340',\n",
       " '3400',\n",
       " '3450',\n",
       " '35',\n",
       " '350',\n",
       " '350d',\n",
       " '35mm',\n",
       " '35th',\n",
       " '36',\n",
       " '360',\n",
       " '3600',\n",
       " '36000',\n",
       " '365',\n",
       " '37',\n",
       " '370',\n",
       " '375',\n",
       " '38',\n",
       " '380',\n",
       " '3800',\n",
       " '380ex',\n",
       " '3820',\n",
       " '384',\n",
       " '38c',\n",
       " '38dd',\n",
       " '38ddd',\n",
       " '39',\n",
       " '3am',\n",
       " '3btech',\n",
       " '3ccd',\n",
       " '3d',\n",
       " '3g',\n",
       " '3ghz',\n",
       " '3in1',\n",
       " '3m',\n",
       " '3mm',\n",
       " '3mp',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3rds',\n",
       " '3t',\n",
       " '3weeks',\n",
       " '3x',\n",
       " '3x28',\n",
       " '3x30',\n",
       " '3yo',\n",
       " '3yr',\n",
       " '3yrs',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '400mm',\n",
       " '40gb',\n",
       " '40mm',\n",
       " '40mph',\n",
       " '40s',\n",
       " '40th',\n",
       " '41',\n",
       " '410',\n",
       " '418',\n",
       " '42',\n",
       " '420ex',\n",
       " '42nd',\n",
       " '43',\n",
       " '430ex',\n",
       " '438',\n",
       " '44',\n",
       " '4482b',\n",
       " '45',\n",
       " '450',\n",
       " '4500',\n",
       " '451',\n",
       " '46',\n",
       " '4600',\n",
       " '461',\n",
       " '47',\n",
       " '471',\n",
       " '47th',\n",
       " '48',\n",
       " '480',\n",
       " '480mm',\n",
       " '485',\n",
       " '48mb',\n",
       " '49',\n",
       " '499',\n",
       " '4a',\n",
       " '4c',\n",
       " '4gb',\n",
       " '4ghz',\n",
       " '4mins',\n",
       " '4mm',\n",
       " '4mp',\n",
       " '4oz',\n",
       " '4runner',\n",
       " '4th',\n",
       " '4x',\n",
       " '4x3',\n",
       " '4x4',\n",
       " '4x4s',\n",
       " '4x6',\n",
       " '4yr',\n",
       " '4yrs',\n",
       " '50',\n",
       " '500',\n",
       " '5000',\n",
       " '500gb',\n",
       " '501',\n",
       " '50mm',\n",
       " '50s',\n",
       " '50th',\n",
       " '51',\n",
       " '510',\n",
       " '512',\n",
       " '512mb',\n",
       " '515',\n",
       " '51598',\n",
       " '52',\n",
       " '5200',\n",
       " '52mm',\n",
       " '53',\n",
       " '5300',\n",
       " '54',\n",
       " '55',\n",
       " '550',\n",
       " '550ex',\n",
       " '555',\n",
       " '55mm',\n",
       " '56',\n",
       " '56k',\n",
       " '57',\n",
       " '5700',\n",
       " '571',\n",
       " '58',\n",
       " '580',\n",
       " '580ex',\n",
       " '59',\n",
       " '5900',\n",
       " '599',\n",
       " '5d',\n",
       " '5fps',\n",
       " '5ft',\n",
       " '5g',\n",
       " '5hrs',\n",
       " '5k',\n",
       " '5lb',\n",
       " '5lbs',\n",
       " '5m',\n",
       " '5mm',\n",
       " '5mp',\n",
       " '5th',\n",
       " '5x',\n",
       " '5x14',\n",
       " '5x7',\n",
       " '5yr',\n",
       " '5yrs',\n",
       " '60',\n",
       " '600',\n",
       " '6000',\n",
       " '604',\n",
       " '60gb',\n",
       " '60ish',\n",
       " '60mph',\n",
       " '60s',\n",
       " '61',\n",
       " '62',\n",
       " '624',\n",
       " '6255i',\n",
       " '63',\n",
       " '6330',\n",
       " '64',\n",
       " '640',\n",
       " '640x480',\n",
       " '64bit',\n",
       " '65',\n",
       " '650',\n",
       " '65cm',\n",
       " '66',\n",
       " '666',\n",
       " '67',\n",
       " '6700',\n",
       " '67mm',\n",
       " '68',\n",
       " '680',\n",
       " '6800',\n",
       " '69',\n",
       " '6aa',\n",
       " '6am',\n",
       " '6ft',\n",
       " '6g',\n",
       " '6mm',\n",
       " '6mo',\n",
       " '6mp',\n",
       " '6th',\n",
       " '6v',\n",
       " '6x',\n",
       " '70',\n",
       " '700',\n",
       " '7000',\n",
       " '700mm',\n",
       " '700p',\n",
       " '700w',\n",
       " '70lbs',\n",
       " '70mm',\n",
       " '70s',\n",
       " '71',\n",
       " '710',\n",
       " '7100',\n",
       " '712c',\n",
       " '7135',\n",
       " '71450',\n",
       " '7180xl',\n",
       " '72',\n",
       " '720',\n",
       " '720p',\n",
       " '7290',\n",
       " '73',\n",
       " '730',\n",
       " '74',\n",
       " '743',\n",
       " '75',\n",
       " '750',\n",
       " '76',\n",
       " '76cm',\n",
       " '77',\n",
       " '78',\n",
       " '79',\n",
       " '7900',\n",
       " '7mm',\n",
       " '7th',\n",
       " '7yr',\n",
       " '80',\n",
       " '800',\n",
       " '8000',\n",
       " '800x600',\n",
       " '802',\n",
       " '8025',\n",
       " '803',\n",
       " '8061',\n",
       " '80asa',\n",
       " '80gb',\n",
       " '80s',\n",
       " '81',\n",
       " '812',\n",
       " '8125',\n",
       " '817',\n",
       " '82',\n",
       " '83',\n",
       " '8300',\n",
       " '84',\n",
       " '8400',\n",
       " '85',\n",
       " '850',\n",
       " '8525',\n",
       " '85mm',\n",
       " '86',\n",
       " '8600',\n",
       " '8610',\n",
       " '87',\n",
       " '8700',\n",
       " '8700c',\n",
       " '8701',\n",
       " '88',\n",
       " '880',\n",
       " '8800',\n",
       " '89',\n",
       " '890',\n",
       " '8985',\n",
       " '8995',\n",
       " '8am',\n",
       " '8cm',\n",
       " '8f',\n",
       " '8ft',\n",
       " '8gb',\n",
       " '8l',\n",
       " '8lbs',\n",
       " '8mb',\n",
       " '8mm',\n",
       " '8oz',\n",
       " '8th',\n",
       " '8x',\n",
       " '8x10',\n",
       " '8x42',\n",
       " '8yo',\n",
       " '8yrs',\n",
       " '90',\n",
       " '900',\n",
       " '9000',\n",
       " '900mhz',\n",
       " '909',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '91cm',\n",
       " '92',\n",
       " '93',\n",
       " '9300',\n",
       " '94',\n",
       " '9400',\n",
       " '95',\n",
       " '950',\n",
       " '9500',\n",
       " '96',\n",
       " '960',\n",
       " '968',\n",
       " '97',\n",
       " '970p',\n",
       " '98',\n",
       " '9891',\n",
       " '98se',\n",
       " '99',\n",
       " '991',\n",
       " '992',\n",
       " '9am',\n",
       " '9mo',\n",
       " '9oz',\n",
       " '9th',\n",
       " '9v',\n",
       " '9x44',\n",
       " '_____',\n",
       " 'a1',\n",
       " 'a1000',\n",
       " 'a1500',\n",
       " 'a2',\n",
       " 'a3',\n",
       " 'a510',\n",
       " 'a520',\n",
       " 'a530',\n",
       " 'a640',\n",
       " 'a670',\n",
       " 'a70',\n",
       " 'a710',\n",
       " 'a90',\n",
       " 'a900',\n",
       " 'a95',\n",
       " 'a950',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aaas',\n",
       " 'aalecky',\n",
       " 'aargh',\n",
       " 'aaron',\n",
       " 'aas',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abandonment',\n",
       " 'abate',\n",
       " 'abba',\n",
       " 'abbey',\n",
       " 'abbreviated',\n",
       " 'abbreviations',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abdul',\n",
       " 'abel',\n",
       " 'aberration',\n",
       " 'abiding',\n",
       " 'abilites',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'abilty',\n",
       " 'abit',\n",
       " 'able',\n",
       " 'ableton',\n",
       " 'ablility',\n",
       " 'ablum',\n",
       " 'abnormal',\n",
       " 'abnormally',\n",
       " 'aboard',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'abortion',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'abraham',\n",
       " 'abrams',\n",
       " 'abrasive',\n",
       " 'abreast',\n",
       " 'abridged',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'abs',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absoloutely',\n",
       " 'absoluta',\n",
       " 'absolute',\n",
       " 'absolutelly',\n",
       " 'absolutely',\n",
       " 'absolutes',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absorb',\n",
       " 'absorbant',\n",
       " 'absorbed',\n",
       " 'absorbency',\n",
       " 'absorbent',\n",
       " 'absorber',\n",
       " 'absorbers',\n",
       " 'absorbing',\n",
       " 'absorbs',\n",
       " 'absorption',\n",
       " 'absoultely',\n",
       " 'absoutely',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdities',\n",
       " 'absurdity',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abuy4u',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'acc',\n",
       " 'accelerated',\n",
       " 'acceleration',\n",
       " 'accent',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuated',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptably',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'accesible',\n",
       " 'accesories',\n",
       " 'accesory',\n",
       " 'access',\n",
       " 'accessable',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessories',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accidentaly',\n",
       " 'accidently',\n",
       " 'accidents',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accomodate',\n",
       " 'accomodated',\n",
       " 'accomodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompaning',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplice',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishes',\n",
       " 'accomplishment',\n",
       " 'accomplishments',\n",
       " 'accord',\n",
       " 'accordian',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'account',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'accounts',\n",
       " 'accoustic',\n",
       " 'accout',\n",
       " 'accoutrements',\n",
       " 'accross',\n",
       " 'accu',\n",
       " 'accumulate',\n",
       " 'accumulated',\n",
       " 'accumulates',\n",
       " 'accumulating',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusations',\n",
       " 'accused',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'accutane',\n",
       " 'ace',\n",
       " 'acessories',\n",
       " 'ache',\n",
       " 'ached',\n",
       " 'aches',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achievements',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'achingly',\n",
       " 'achy',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acids',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledging',\n",
       " 'acknowlege',\n",
       " 'ackroyd',\n",
       " 'ackward',\n",
       " 'acne',\n",
       " 'acnefree',\n",
       " 'acomplish',\n",
       " 'acorn',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acqua',\n",
       " 'acquaintance',\n",
       " 'acquainted',\n",
       " 'acquiesce',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquires',\n",
       " 'acquiring',\n",
       " 'acquisition',\n",
       " 'acquisitions',\n",
       " 'acre',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acrobat',\n",
       " 'acronis',\n",
       " 'acrylic',\n",
       " 'acsess',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'activated',\n",
       " 'activates',\n",
       " 'activating',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activision',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activites',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'actron',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actuations',\n",
       " 'actully',\n",
       " 'acura',\n",
       " 'acurate',\n",
       " 'acurately',\n",
       " 'acutally',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adagio',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adaptations',\n",
       " 'adaptec',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'adaptor',\n",
       " 'adaptors',\n",
       " 'adapts',\n",
       " 'adaware',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addictingly',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " ...]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All X features names in count_vectorizer\n",
    "X_names = count_vec.get_feature_names()\n",
    "X_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38548, 29179)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_df = pd.DataFrame(X_count_vec.toarray(),columns = X_names)\n",
    "X_count_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zorbitt</th>\n",
       "      <th>zoya</th>\n",
       "      <th>zr</th>\n",
       "      <th>zr800</th>\n",
       "      <th>zucchero</th>\n",
       "      <th>zukav</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zune</th>\n",
       "      <th>zyliss</th>\n",
       "      <th>zymol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  00am  00pm  01  02  03  04  05  ...  zorbitt  zoya  zr  \\\n",
       "0   0    0    0     0     0   0   0   0   0   0  ...        0     0   0   \n",
       "1   0    0    0     0     0   0   0   0   0   0  ...        0     0   0   \n",
       "2   0    0    0     0     0   0   0   0   0   0  ...        0     0   0   \n",
       "3   0    0    0     0     0   0   0   0   0   0  ...        0     0   0   \n",
       "4   2    0    0     0     0   0   0   0   0   0  ...        0     0   0   \n",
       "\n",
       "   zr800  zucchero  zukav  zulu  zune  zyliss  zymol  \n",
       "0      0         0      0     0     0       0      0  \n",
       "1      0         0      0     0     0       0      0  \n",
       "2      0         0      0     0     0       0      0  \n",
       "3      0         0      0     0     0       0      0  \n",
       "4      0         0      0     0     0       0      0  \n",
       "\n",
       "[5 rows x 29179 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data in train ad test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_count_df,y,test_size = 0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28911, 29179)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9637, 29179)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Naive Bayes Classifier\n",
    "#Using Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "model = gnb.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5511051156999066"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3356,  768],\n",
       "       [3558, 1955]], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model = confusion_matrix(y_test,y_pred)\n",
    "score_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5511051156999066"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model = (score_model[0][0]+score_model[1][1])/(sum(score_model[0])+sum(score_model[1]))\n",
    "accuracy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4488948843000934"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_model = (score_model[0][1]+score_model[1][0])/(sum(score_model[0])+sum(score_model[1]))\n",
    "error_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Multinomial because there are multiple features\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "model2 = clf.fit(X_train,y_train)\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111445470582132"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3185,  939],\n",
       "       [ 881, 4632]], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model2 = confusion_matrix(y_test,y_pred2)\n",
    "score_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8111445470582132"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model2 = (score_model2[0][0]+score_model2[1][1])/(sum(score_model2[0])+sum(score_model2[1]))\n",
    "accuracy_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18885545294178685"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_model2 = (score_model2[0][1]+score_model2[1][0])/(sum(score_model2[0])+sum(score_model2[1]))\n",
    "error_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For checking the classifcation of a new review, we need to make sure that our model is trained well enough to compensate for the difference in tokens between heterogeneous datasets from different sources. For that, we probably need more data for training. Other than that, we may not be able to correctly classify heterogeneous samples (with different token attributes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing one new sample for classification after training\n",
    "def prepare_rev(review):\n",
    "    review=review.values.flatten()\n",
    "    review_cat = ''\n",
    "    for element in review:\n",
    "        review_cat += element\n",
    "    \n",
    "    review_words = review_cat.split(\" \")\n",
    "    \n",
    "    rev_text = review_words\n",
    "    rev_one_string = \" \".join(rev_text)\n",
    "    rev_one_string = rev_one_string.replace(' ,',',')\n",
    "    rev_one_string = rev_one_string.replace(' .',',')\n",
    "    rev_one_string = rev_one_string.replace(\"\\' \",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_one_string\n",
    "\n",
    "    rev_list=[]\n",
    "    rev_list.append(rev_one_string)\n",
    "\n",
    "    count_vec = CountVectorizer(lowercase = True, stop_words = 'english', min_df = 1)\n",
    "\n",
    "    X_count_vec = count_vec.fit_transform(rev_list)\n",
    "\n",
    "    X_names = count_vec.get_feature_names()\n",
    "    X_names\n",
    "\n",
    "    X_count_df = pd.DataFrame(X_count_vec.toarray(),columns = X_names)\n",
    "    X_count_df.shape\n",
    "    \n",
    "    common=X_test.columns.intersection(X_count_df.columns)\n",
    "    result = pd.DataFrame(0,index=range(1),columns = X_train.columns)\n",
    "    \n",
    "    for col in common:\n",
    "        try:\n",
    "            result.iloc[0][col]=X_count_df.iloc[0][col]\n",
    "        except:\n",
    "            continue\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting category on new sample based on the trained model\n",
    "def predict_category(review, model = model2):\n",
    "    test_df = prepare_rev(review)\n",
    "    pred = model.predict(test_df)\n",
    "    if pred == 0:\n",
    "        return \"The review is negative\"\n",
    "    else:\n",
    "        return \"The review is positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\weka\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "review = pd.read_table(\"sample amazon negative review.txt\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  007  00am  00pm  01  02  03  04  05  ...  zorbitt  zoya  zr  \\\n",
      "0   0    0    0     0     0   0   0   0   0   0  ...        0     0   0   \n",
      "\n",
      "   zr800  zucchero  zukav  zulu  zune  zyliss  zymol  \n",
      "0      0         0      0     0     0       0      0  \n",
      "\n",
      "[1 rows x 29179 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The review is negative'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category(review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
