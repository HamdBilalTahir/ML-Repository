{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brown', 'conll2000.zip', 'brown.zip', 'wordnet.zip', 'movie_reviews', 'conll2000', 'wordnet', 'movie_reviews.zip']\n"
     ]
    }
   ],
   "source": [
    "# nltk.download() \n",
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import movie reviews and check categories\n",
    "from nltk.corpus import movie_reviews\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_rev = movie_reviews.fileids('pos')\n",
    "len(pos_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_rev = movie_reviews.fileids('neg')\n",
    "len(neg_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos/cv000_29590.txt',\n",
       " 'pos/cv001_18431.txt',\n",
       " 'pos/cv002_15918.txt',\n",
       " 'pos/cv003_11664.txt',\n",
       " 'pos/cv004_11636.txt',\n",
       " 'pos/cv005_29443.txt',\n",
       " 'pos/cv006_15448.txt',\n",
       " 'pos/cv007_4968.txt',\n",
       " 'pos/cv008_29435.txt',\n",
       " 'pos/cv009_29592.txt']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#List positive review files\n",
    "pos_rev[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['films', 'adapted', 'from', 'comic', 'books', 'have', ...]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select one positive review\n",
    "rev = movie_reviews.words('pos/cv000_29590.txt')\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse and append tokens to a new list\n",
    "rev_list = []\n",
    "for rev in neg_rev:\n",
    "    rev_text_neg = movie_reviews.words(rev)\n",
    "    rev_one_string = \" \".join(rev_text_neg)\n",
    "    rev_one_string = rev_one_string.replace(' ,',',')\n",
    "    rev_one_string = rev_one_string.replace(' .',',')\n",
    "    rev_one_string = rev_one_string.replace(\"\\' \",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_list.append(rev_one_string)\n",
    "# rev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the happy bastard\\'s quick movie review damn that y2k bug, it\\'s got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on, little do they know the power within,,, going for the gore and bringing on a few action sequences here and there, virus still feels very empty, like a movie going for all flash and no substance, we don\\'t know why the crew was really out in the middle of nowhere, we don\\'t know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ), and, of course, we don\\'t know why donald sutherland is stumbling around drunkenly throughout, here, it\\'s just \" hey, let\\'s chase these people around with some robots \", the acting is below average, even from the likes of curtis, you\\'re more likely to get a kick out of her work in halloween h20, sutherland is wasted and baldwin, well, he\\'s acting like a baldwin, of course, the real star here are stan winston\\'s robot design, some schnazzy cgi, and the occasional good gore shot, like picking into someone\\'s brain, so, if robots and body parts really turn you on, here\\'s your movie, otherwise, it\\'s pretty much a sunken ship of a movie,'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rev in pos_rev:\n",
    "    rev_text_pos = movie_reviews.words(rev)\n",
    "    rev_one_string = \" \".join(rev_text_pos)\n",
    "    rev_one_string = rev_one_string.replace(' ,',',')\n",
    "    rev_one_string = rev_one_string.replace(' .',',')\n",
    "    rev_one_string = rev_one_string.replace(\"\\' \",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_list.append(rev_one_string)\n",
    "# rev_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_targets = np.zeros((1000,),dtype = np.int)\n",
    "pos_targets = np.ones((1000,),dtype = np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = []\n",
    "for neg_tar in neg_targets:\n",
    "    target_list.append(neg_tar)\n",
    "for pos_tar in pos_targets:\n",
    "    target_list.append(pos_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.Series(target_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use bag of words or count vectorizer to make features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vec = CountVectorizer(lowercase = True, stop_words = 'english', min_df = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_count_vec = count_vec.fit_transform(rev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23784)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00', '000', '007', '05', '10', '100', '1000', '100m', '101', '102']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All X features names in count_vectorizer\n",
    "X_names = count_vec.get_feature_names()\n",
    "X_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 23784)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_df = pd.DataFrame(X_count_vec.toarray(),columns = X_names)\n",
    "X_count_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>100m</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zoot</th>\n",
       "      <th>zorg</th>\n",
       "      <th>zorro</th>\n",
       "      <th>zucker</th>\n",
       "      <th>zuko</th>\n",
       "      <th>zwick</th>\n",
       "      <th>zwigoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  007  05  10  100  1000  100m  101  102   ...     zoom  zooming  \\\n",
       "0   0    0    0   0  10    0     0     0    0    0   ...        0        0   \n",
       "1   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "2   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "3   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "4   0    0    0   0   0    0     0     0    0    0   ...        0        0   \n",
       "\n",
       "   zooms  zoot  zorg  zorro  zucker  zuko  zwick  zwigoff  \n",
       "0      0     0     0      0       0     0      0        0  \n",
       "1      0     0     0      0       0     0      0        0  \n",
       "2      0     0     0      0       0     0      0        0  \n",
       "3      0     0     0      0       0     0      0        0  \n",
       "4      0     0     0      0       0     0      0        0  \n",
       "\n",
       "[5 rows x 23784 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_count_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data in train ad test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X_count_df,y,test_size = 0.25, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 23784)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23784)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use Naive Bayes Classifier\n",
    "#Using Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "model = gnb.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[173,  85],\n",
       "       [ 88, 154]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model = confusion_matrix(y_test,y_pred)\n",
    "score_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.654"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model = (score_model[0][0]+score_model[1][1])/(sum(score_model[0])+sum(score_model[1]))\n",
    "accuracy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.346"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_model = (score_model[0][1]+score_model[1][0])/(sum(score_model[0])+sum(score_model[1]))\n",
    "error_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Multinomial because there are multiple features\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "model2 = clf.fit(X_train,y_train)\n",
    "y_pred2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[213,  45],\n",
       "       [ 56, 186]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_model2 = confusion_matrix(y_test,y_pred2)\n",
    "score_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.798"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model2 = (score_model2[0][0]+score_model2[1][1])/(sum(score_model2[0])+sum(score_model2[1]))\n",
    "accuracy_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.202"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_model2 = (score_model2[0][1]+score_model2[1][0])/(sum(score_model2[0])+sum(score_model2[1]))\n",
    "error_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For checking the classifcation of a new review, we need to make sure that our model is trained well enough to compensate for the difference in tokens between heterogeneous datasets from different sources. For that, we probably need more data for training. Other than that, we may not be able to correctly classify heterogeneous samples (with different token attributes). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing one new sample for clasification after training\n",
    "def prepare_rev(review):\n",
    "    review=review.values.flatten()\n",
    "    review_cat = ''\n",
    "    for element in review:\n",
    "        review_cat += element\n",
    "    \n",
    "    review_words = review_cat.split(\" \")\n",
    "    \n",
    "    rev_text = review_words\n",
    "    rev_one_string = \" \".join(rev_text)\n",
    "    rev_one_string = rev_one_string.replace(' ,',',')\n",
    "    rev_one_string = rev_one_string.replace(' .',',')\n",
    "    rev_one_string = rev_one_string.replace(\"\\' \",\"'\")\n",
    "    rev_one_string = rev_one_string.replace(\" \\'\",\"'\")\n",
    "    rev_one_string\n",
    "\n",
    "    rev_list=[]\n",
    "    rev_list.append(rev_one_string)\n",
    "\n",
    "    count_vec = CountVectorizer(lowercase = True, stop_words = 'english', min_df = 1)\n",
    "\n",
    "    X_count_vec = count_vec.fit_transform(rev_list)\n",
    "\n",
    "    X_names = count_vec.get_feature_names()\n",
    "    X_names\n",
    "\n",
    "    X_count_df = pd.DataFrame(X_count_vec.toarray(),columns = X_names)\n",
    "    X_count_df.shape\n",
    "    \n",
    "    common=X_test.columns.intersection(X_count_df.columns)\n",
    "    result = pd.DataFrame(0,index=range(1),columns = X_train.columns)\n",
    "    \n",
    "    for col in common:\n",
    "        try:\n",
    "            result.iloc[0][col]=X_count_df.iloc[0][col]\n",
    "        except:\n",
    "            continue\n",
    "    print(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting category on new sample based on the trained model\n",
    "def predict_category(review, model = model2):\n",
    "    test_df = prepare_rev(review)\n",
    "    pred = model.predict(test_df)\n",
    "    if pred == 0:\n",
    "        return \"The review is negative\"\n",
    "    else:\n",
    "        return \"The review is positive\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot : two teen couples go to a church party ,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they get into an accident .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one of the guys dies , but his girlfriend cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what's the deal ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>watch the movie and \" sorta \" find out . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>critique : a mind-fuck movie for the teen gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>which is what makes this review an even harder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>they seem to have taken this pretty neat conce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>so what are the problems with the movie ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>well , its main problem is that it's simply to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  plot : two teen couples go to a church party ,...\n",
       "1                       they get into an accident . \n",
       "2  one of the guys dies , but his girlfriend cont...\n",
       "3                                 what's the deal ? \n",
       "4      watch the movie and \" sorta \" find out . . . \n",
       "5  critique : a mind-fuck movie for the teen gene...\n",
       "6  which is what makes this review an even harder...\n",
       "7  they seem to have taken this pretty neat conce...\n",
       "8         so what are the problems with the movie ? \n",
       "9  well , its main problem is that it's simply to..."
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = pd.read_table(\"sample movie review1.txt\",header = None)\n",
    "review.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   00  000  007  05  10  100  1000  100m  101  102   ...     zoom  zooming  \\\n",
      "0   0    0    0   0  10    0     0     0    0    0   ...        0        0   \n",
      "\n",
      "   zooms  zoot  zorg  zorro  zucker  zuko  zwick  zwigoff  \n",
      "0      0     0     0      0       0     0      0        0  \n",
      "\n",
      "[1 rows x 23784 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The review is negative'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_category(review)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
